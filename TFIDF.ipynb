{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Import_Data_Process.ipynb before running this notebook to get pre-processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages/Dataset & Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary Packages\n",
    "\n",
    "from implicit.nearest_neighbours import tfidf_weight\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from numpy import bincount, log, sqrt\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "import implicit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data files\n",
    "df_order_products_prior = pd.read_csv(\"order_products__prior.csv\")\n",
    "df_order_products_train = pd.read_csv(\"order_products__train.csv\")\n",
    "df_orders = pd.read_csv(\"orders.csv\") \n",
    "df_products = pd.read_csv(\"products.csv\")\n",
    "\n",
    "# Merge prior orders and products\n",
    "df_merged_prior = pd.merge(df_order_products_prior, df_products, on=\"product_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read user_products and product_frequency from disk\n",
    "df_prior_user_products = pd.read_pickle(\"df_user_products_prior.pkl\")\n",
    "df_product_frequency = pd.read_pickle(\"df_product_frequency.pkl\")\n",
    "df_product_frequency = pd.DataFrame(df_product_frequency).rename(columns={\"product_id\": \"frequency\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[196, 25133, 38928, 26405, 39657, 10258, 13032...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[22963, 7963, 16589, 32792, 41787, 22825, 1364...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>[15349, 19057, 16185, 21413, 20843, 20114, 482...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>[12053, 47272, 37999, 13198, 43967, 40852, 176...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>[15937, 5539, 10960, 23165, 22247, 4853, 27104...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                         product_id\n",
       "0        1  [196, 25133, 38928, 26405, 39657, 10258, 13032...\n",
       "1        2  [22963, 7963, 16589, 32792, 41787, 22825, 1364...\n",
       "2        5  [15349, 19057, 16185, 21413, 20843, 20114, 482...\n",
       "3        7  [12053, 47272, 37999, 13198, 43967, 40852, 176...\n",
       "4        8  [15937, 5539, 10960, 23165, 22247, 4853, 27104..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read from saved test data\n",
    "test_data_path = \"user_products__test.csv\"\n",
    "df_user_products_test = pd.read_csv(test_data_path)\n",
    "df_user_products_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Necessary Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make user_product dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_product_prior(filepath, df_orders, df_order_products_prior):\n",
    "    \"\"\"\n",
    "    Generates a dataframe of users and their purchase of products\n",
    "    \"\"\"\n",
    "    order_user = df_orders.loc[df_orders.eval_set == \"prior\"]\n",
    "    order_user = order_user[[\"order_id\", \"user_id\"]]\n",
    "    \n",
    "    \n",
    "    # merge order:duplic user_id with duplic order_id:product_id on order_id\n",
    "    # take out order id so only duplic user_id: product_id remains\n",
    "    # Add quantity column\n",
    "    df_merged = pd.merge(order_user, df_order_products_prior[[\"order_id\", \"product_id\"]], on=\"order_id\")\n",
    "    user_product = df_merged[[\"user_id\", \"product_id\"]]\n",
    "    user_product = user_product.groupby([\"user_id\", \"product_id\"]).size().reset_index()\n",
    "    user_product = user_product.rename(columns={0:\"quantity\"})\n",
    "    \n",
    "    # Write to disk\n",
    "    user_product.to_csv(filepath, index_label=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataframe of users, products and quantity bought (prior)\n",
    "matrix_df_path = \"user_products__prior.csv\"\n",
    "if not Path(matrix_df_path).is_file():\n",
    "    user_product_prior(matrix_df_path, df_orders, df_order_products_prior)\n",
    "df_user_product_prior = pd.read_csv(matrix_df_path)\n",
    "df_user_product_prior[\"user_id\"] = df_user_product_prior[\"user_id\"].astype(\"category\")\n",
    "df_user_product_prior[\"product_id\"] = df_user_product_prior[\"product_id\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10258</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12427</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13032</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id product_id  quantity\n",
       "0       1        196        10\n",
       "1       1      10258         9\n",
       "2       1      10326         1\n",
       "3       1      12427        10\n",
       "4       1      13032         3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_product_prior.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make weighted utility matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_user_matrix(matrix_path, df_user_product_prior):\n",
    "    \"\"\"\n",
    "    Generates utility matrix based on purchase history. Rows: products Columns: users\n",
    "    \"\"\"\n",
    "    # Make the dataframe a sparse matrix\n",
    "    product_user_matrix = sparse.coo_matrix((df_user_product_prior[\"quantity\"],\n",
    "                                            (df_user_product_prior[\"product_id\"].cat.codes.copy(),\n",
    "                                             df_user_product_prior[\"user_id\"].cat.codes.copy())))\n",
    "    \n",
    "    sparse.save_npz(matrix_path, product_user_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the `product x user` matrix\n",
    "matrix_path = \"product_user_matrix.npz\"\n",
    "if not Path(matrix_path).is_file():\n",
    "    product_user_matrix(matrix_path, df_user_product_prior)\n",
    "product_user_matrix = sparse.load_npz(matrix_path).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User=1 bought product=196 10 times\n",
    "product_user_matrix[195, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make user x product matrix\n",
    "user_product_matrix = product_user_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be 10\n",
    "user_product_matrix[0,195]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(tf):\n",
    "    \"\"\"\n",
    "    Generates TF-IDF weight matrix with given user x product matrix\n",
    "    Document = user\n",
    "    Term = product\n",
    "    tf = count of term in document, squared (common practice)\n",
    "    idf = log(# of documents/# of documents with t + 1). Plus one on denominator to avoid dividing by 0.\n",
    "    \"\"\"\n",
    "    tf_idf = coo_matrix(tf)\n",
    "\n",
    "    # Number of users\n",
    "    N = float(tf_idf.shape[0])\n",
    "    \n",
    "    # bincount = nonzero elements\n",
    "    # bincount(tf_idf.col) = # of users who bought the product\n",
    "    no_users_prod = bincount(tf_idf.col)\n",
    "    idf = log(N / (1 + no_users_prod))\n",
    "\n",
    "    # Squaring tf is a common practice\n",
    "    tf_idf.data = sqrt(tf_idf.data) * idf[tf_idf.col]\n",
    "    \n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = tfidf(user_product_matrix)\n",
    "# convert to Compressed Sparse Row format\n",
    "tf_idf = tf_idf.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Recommendation\n",
    "def recommend(target_user, cos_sim, K, N) :\n",
    "    \"\"\"\n",
    "    Arguments: target_user (row of tf_idf matrix), cosine similarity vector, number of similar users to consider (K),\n",
    "    number of products to recommend (N)\n",
    "    Generates N recommendations for target user\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select K similar users with the highest cosine similarity score (most similar)\n",
    "    K_similar = heapq.nlargest(K+1, range(len(cos_sim)), cos_sim.take)\n",
    "    \n",
    "    # Find products bought by the target user\n",
    "    products_target_user = df_prior_user_products.loc[df_prior_user_products['user_id'] == target_user_id].product_id\n",
    "    products_target_user = set(products_target_user.tolist()[0])\n",
    "\n",
    "    recommendations = []\n",
    "    # Make recommended items list of length N\n",
    "    # Ensures recommendations from users who are most similar are included\n",
    "    for similar_user in K_similar:\n",
    "        products_similar_user = df_prior_user_products.loc[df_prior_user_products['user_id'] == similar_user + 1]\n",
    "        product_id_sim_user = products_similar_user['product_id']\n",
    "        product_id_sim_user = product_id_sim_user.tolist()[0]\n",
    "        # Look at all products bought by the similar user the target user did not buy\n",
    "        sim_recs = set(product_id_sim_user) - products_target_user\n",
    "        # Skip if looking at target user or if there are no recommendations from similar user\n",
    "        if similar_user == target_user_id or not sim_recs: \n",
    "            continue\n",
    "        # Add recommended items to total recommendation list\n",
    "        recommendations.extend(sim_recs)\n",
    "        if len(recommendations) > N:\n",
    "            break\n",
    "        \n",
    "    # Pick the top N popularity (overall sales) to recommend\n",
    "    heap = []\n",
    "    for product in recommendations:\n",
    "        heapq.heappush(heap, (df_product_frequency.loc[product]['frequency'], product))\n",
    "        if len(heap) > N:\n",
    "            heapq.heappop(heap)\n",
    "            \n",
    "    return products_target_user, [item[1] for item in heap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test one user\n",
    "\n",
    "target_user_index = 10\n",
    "target_user = tf_idf[target_user_index - 1]\n",
    "\n",
    "# Cosine similarity vector of target user\n",
    "cos_sim = cosine_similarity(tf_idf, target_user, False).toarray()\n",
    "# Pick 20 neighbors and 10 products to recommend\n",
    "# Returns products the target user already bought and their recommendations\n",
    "products_target, recommendations = recommend(target_user, cos_sim, 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Recommendations for User 10:\n",
      "[8518, 4605, 45066, 22935, 5876, 39275, 8277, 47209, 21903, 47766]\n",
      "\n",
      "User 10 already bought:\n",
      "{36865, 20995, 13829, 43014, 11782, 18441, 47626, 5646, 22035, 27156, 15392, 32299, 34358, 15937, 7746, 19019, 48204, 45664, 30305, 26209, 24184, 9339, 23165, 42625, 35973, 48775, 5769, 9871, 14992, 42647, 20632, 40604, 15011, 28842, 47788, 21174, 5818, 13512, 19678, 18656, 42736, 28928, 40706, 41220, 260, 31506, 24852, 47380, 32537, 30489, 13083, 8988, 22825, 37687, 4920, 16185, 28986, 26940, 13629, 11068, 44359, 23879, 21833, 5450, 25931, 34126, 34128, 36695, 43352, 42342, 44910, 28535, 36735, 17794, 46979, 35725, 13198, 38293, 13212, 16797, 17828, 47526, 20920, 15290, 47042, 39877, 45007, 7632, 16857, 27104, 31717, 47591, 23541, 1529}\n"
     ]
    }
   ],
   "source": [
    "print('10 Recommendations for User {}:'.format(target_user_index))\n",
    "print(recommendations)\n",
    "print()\n",
    "print('User {} already bought:'.format(target_user_index))\n",
    "print(products_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_popular(k, df_merged_prior):\n",
    "    \"\"\"\n",
    "    Returns the `k` most popular products based on purchase count\n",
    "    \"\"\"\n",
    "    pop_prods = df_merged_prior[\"product_id\"].value_counts()[0:10]\n",
    "    pop_prods_id = pop_prods.index\n",
    "    return pop_prods_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([24852, 13176, 21137, 21903, 47209, 47766, 47626, 16797, 26209,\n",
       "            27845],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the 10 most popular products\n",
    "popular_products = k_popular(10, df_merged_prior)\n",
    "popular_products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline F-1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_products(row):\n",
    "    \"\"\"\n",
    "    Given a row in the test dataset\n",
    "    Returns the list of new products purchased\n",
    "    \"\"\"\n",
    "    actual = row[\"product_id\"][1:-1]\n",
    "    actual = set([int(p.strip()) for p in actual.strip().split(\",\")])\n",
    "    products_target_user = df_prior_user_products.loc[df_prior_user_products['user_id'] == row[\"user_id\"]].product_id\n",
    "    liked = set(products_target_user.tolist()[0])\n",
    "    return actual - liked\n",
    "\n",
    "def recall_score(actual, pred):\n",
    "    if len(actual) == 0:\n",
    "        return 0\n",
    "    actual, pred = set(actual), set(pred)\n",
    "    return len(actual.intersection(pred)) / len(actual)\n",
    "\n",
    "def precision_score(actual, pred):\n",
    "    if len(actual) == 0:\n",
    "        return 0\n",
    "    actual, pred = set(actual), set(pred)\n",
    "    return len(actual.intersection(pred)) / len(pred)\n",
    "\n",
    "def popular_recommend(row):\n",
    "    \"\"\"\n",
    "    Given a row in the test dataset\n",
    "    Returns the f1 score when popular products are recommended\n",
    "    \"\"\"\n",
    "    actual = new_products(row)\n",
    "    recall = recall_score(actual, popular_products)\n",
    "    precision = precision_score(actual, popular_products)\n",
    "\n",
    "    # Avoid division by 0\n",
    "    if precision+recall == 0:\n",
    "        f1 = 0\n",
    "    else:\n",
    "        f1 = 2*precision*recall/(precision+recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline F1 score\n",
    "def baseline_df(filepath, df_user_products_test, subset=None):\n",
    "    start = time.time()\n",
    "    df_eval = df_user_products_test.copy()\n",
    "    \n",
    "    if subset:\n",
    "        df_eval = df_eval.iloc[subset[0]-1:subset[1]-1]\n",
    "    df_eval[\"popular_score\"] = df_eval.apply(popular_recommend, axis=1)\n",
    "    df_eval.to_csv(filepath)\n",
    "    \n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 46.84s\n",
      "Baseline: 1.53%\n"
     ]
    }
   ],
   "source": [
    "# Get baseline numbers\n",
    "REBUILD_EVAL_DF = True\n",
    "subset = [1,20000]\n",
    "\n",
    "base_path = \"eval_tfidf_baseline.csv\"\n",
    "if REBUILD_EVAL_DF or not Path(eval_path).exists():\n",
    "    baseline_df(base_path, df_user_products_test, subset=subset)\n",
    "df_eval = pd.read_csv(base_path)\n",
    "\n",
    "# Mean f1 score for baseline\n",
    "baseline_mean_f1 = np.mean(df_eval[\"popular_score\"])\n",
    "print(\"Baseline: {:.2f}%\".format(baseline_mean_f1 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model F-1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_recommend(row):\n",
    "    \"\"\"\n",
    "    Given a row in the test dataset\n",
    "    Returns the F1 score when our model recommends products\n",
    "    \"\"\"\n",
    "    actual = row[\"product_id\"][1:-1]\n",
    "    actual = [int(p.strip()) for p in actual.strip().split(\",\")]\n",
    "    target_user = tf_idf[row[\"user_id\"] - 1]\n",
    "    similarities = cosine_similarity(tf_idf, target_user, False)\n",
    "    cos_vec = similarities.toarray()\n",
    "    productset_target_user, recommended = recommend(target_user, cos_vec, 20, 10)\n",
    "\n",
    "    cur_recall_score = recall_score(actual, recommended)\n",
    "    precision = precision_score(actual,recommended)\n",
    "    \n",
    "    if precision+cur_recall_score == 0:\n",
    "        f1 = 0\n",
    "    else:\n",
    "        f1 = 2*precision*cur_recall_score/(precision+cur_recall_score)\n",
    "    \n",
    "    global count, f1_sum\n",
    "    count += 1; f1_sum += f1\n",
    "    if count%1000 == 0:\n",
    "        print(\"{:.1f}th iteration, current mean of recall = {}\".format(count, f1_sum / count))   \n",
    "    \n",
    "    return f1\n",
    "\n",
    "def build_eval_df(filepath, df_user_products_test, subset=None):\n",
    "    \"\"\"\n",
    "    Builds a dataframe of f1 values of the baseline and our model for all the users\n",
    "    in the test data, and saves its to disk at `filepath`\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    print(\"Building dataframe with f1 values ...\")\n",
    "    \n",
    "    df_eval = df_user_products_test.copy()\n",
    "    if subset:\n",
    "        df_eval = df_eval.iloc[subset[0]-1:subset[1]-1]\n",
    "    df_eval[\"tfidf_score\"] = df_eval.apply(tfidf_recommend, axis=1)\n",
    "    df_eval.to_csv(filepath)\n",
    "    \n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataframe with f1 values ...\n",
      "Completed in 57.84s\n"
     ]
    }
   ],
   "source": [
    "REBUILD_EVAL_DF = True\n",
    "subset = [1,20000]\n",
    "\n",
    "# Counter\n",
    "count = 0\n",
    "f1_sum = 0\n",
    "\n",
    "# Estimated 6-7 hours to complete\n",
    "eval_path = \"eval_tfidf_{}.csv\".format(subset[1] if subset is not None else \"full\")\n",
    "if REBUILD_EVAL_DF or not Path(eval_path).exists():\n",
    "    build_eval_df(eval_path, df_user_products_test, subset=subset)\n",
    "df_eval = pd.read_csv(eval_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 17.89%\n"
     ]
    }
   ],
   "source": [
    "# Mean F-1 Score\n",
    "model_mean_f1 = np.mean(df_eval[\"tfidf_score\"])\n",
    "print(\"Model: {:.2f}%\".format(model_mean_f1 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
